{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "with open(r'C:\\Users\\acer\\Desktop\\Ds\\Data 2018-2023\\Project\\2023\\202300222.json') as fd:\n",
    "    sc = json.load(fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set option to display all rows\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# # Set option to display full content in each cell without truncation\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# # Optionally, set the display width to accommodate wide columns\n",
    "# pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_list = []\n",
    "\n",
    "# Navigate to 'author-group' and ensure it's a list\n",
    "author_groups = sc.get('abstracts-retrieval-response', {}) \\\n",
    "                  .get('item', {}) \\\n",
    "                  .get('bibrecord', {}) \\\n",
    "                  .get('head', {}) \\\n",
    "                  .get('author-group', [])\n",
    "\n",
    "if isinstance(author_groups, dict):\n",
    "    author_groups = [author_groups]\n",
    "\n",
    "for group in author_groups:\n",
    "    authors = group.get('author', [])\n",
    "    if not authors:\n",
    "        continue  # Skip if there are no authors\n",
    "    \n",
    "    affiliation = group.get('affiliation', {})\n",
    "    if not affiliation:\n",
    "        continue  # Skip if affiliation is missing\n",
    "    \n",
    "    aff_id = affiliation.get('@afid', '')\n",
    "    \n",
    "    # Extract organization names\n",
    "    org = affiliation.get('organization', [])\n",
    "    if isinstance(org, dict):\n",
    "        aff_name = org.get('$', '')\n",
    "    elif isinstance(org, list):\n",
    "        aff_name = ', '.join(item.get('$', '') for item in org)\n",
    "    else:\n",
    "        aff_name = ''\n",
    "    \n",
    "    aff_city = affiliation.get('affiliation-city', affiliation.get('city', ''))\n",
    "    aff_country = affiliation.get('affiliation-country', affiliation.get('country', ''))\n",
    "    \n",
    "    for author in authors:\n",
    "        indexed_name = author.get('ce:indexed-name', 'Unknown')\n",
    "        au_list.append((indexed_name, aff_id, aff_name, aff_city, aff_country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = pd.DataFrame(au_list, columns=['name', 'id', 'organization', 'city', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = sc['abstracts-retrieval-response']['item']['bibrecord']['tail']['bibliography']['reference']\n",
    "\n",
    "ref_list = []\n",
    "for ref in references:\n",
    "    ref_id = ref.get('@id', '')\n",
    "    fulltext = ref.get('ref-fulltext', '')\n",
    "    publication_year = ref.get('ref-info', {}).get('ref-publicationyear', {}).get('@first', '')\n",
    "    title = ref.get('ref-info', {}).get('ref-title', {}).get('ref-titletext', '')\n",
    "    source_title = ref.get('ref-info', {}).get('ref-sourcetitle', '')\n",
    "    \n",
    "    authors = ref.get('ref-info', {}).get('ref-authors', {}).get('author', [])\n",
    "    author_names = [author.get('ce:indexed-name', '') for author in authors]\n",
    "    authors_str = ', '.join(author_names)\n",
    "    \n",
    "    ref_list.append({\n",
    "        'id': ref_id,\n",
    "        'fulltext': fulltext,\n",
    "        'year': publication_year,\n",
    "        'title': title,\n",
    "        'source_title': source_title,\n",
    "        'authors': authors_str\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.DataFrame(ref_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = r'C:\\Users\\acer\\Desktop\\Ds\\Data 2018-2023\\Project\\2023'\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.json'):\n",
    "        with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as fd:\n",
    "            sc = json.load(fd)\n",
    "            subject_areas = sc['abstracts-retrieval-response']['subject-areas']['subject-area']\n",
    "            if isinstance(subject_areas, list):\n",
    "                for subject in subject_areas:\n",
    "                    data.append({\n",
    "                        'file_name': file_name,\n",
    "                        'fa': subject.get('@_fa', ''),\n",
    "                        'subject': subject.get('$', ''),\n",
    "                        'code': subject.get('@code', ''),\n",
    "                        'abbrev': subject.get('@abbrev', '')\n",
    "                    })\n",
    "            else:\n",
    "                subject = subject_areas\n",
    "                data.append({\n",
    "                    'file_name': file_name,\n",
    "                    'fa': subject.get('@_fa', ''),\n",
    "                    'subject': subject.get('$', ''),\n",
    "                    'code': subject.get('@code', ''),\n",
    "                    'abbrev': subject.get('@abbrev', '')\n",
    "                })\n",
    "\n",
    "subject_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_subjects(df, subjects):\n",
    "    \"\"\"\n",
    "    Checks if the specified subjects exist in the DataFrame and identifies the files they are in.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame with 'file_name' and 'subject_area' columns.\n",
    "    - subjects (list): List of subject names to search for.\n",
    "\n",
    "    Returns:\n",
    "    - matched_files (list): List of unique file names containing the specified subjects.\n",
    "    - df_matched (pd.DataFrame): DataFrame listing file names and their matched subjects.\n",
    "    \"\"\"\n",
    "    matched_files = []\n",
    "    matched_data = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        # Perform case-insensitive matching\n",
    "        matches = df[df['subject'].str.lower() == subject.lower()]\n",
    "        \n",
    "        if not matches.empty:\n",
    "            # Get unique file names where the subject exists\n",
    "            files = matches['file_name'].unique().tolist()\n",
    "            matched_files.extend(files)\n",
    "            \n",
    "            # Append matched subjects and corresponding file names\n",
    "            for file in files:\n",
    "                matched_data.append({'file_name': file, 'subject': subject})\n",
    "        else:\n",
    "            print(f\"Subject '{subject}' does not exist.\")\n",
    "\n",
    "    # Remove duplicate file names\n",
    "    matched_files = list(set(matched_files))\n",
    "\n",
    "    # Create a DataFrame for matched subjects and files\n",
    "    df_matched = pd.DataFrame(matched_data)\n",
    "\n",
    "    return matched_files, df_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_to_search = ['finance','Economics and Econometrics','Economics, Econometrics and Finance (all)']\n",
    "matched_files, df_matched_subjects = check_subjects(subject_df, subjects_to_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Files containing the specified subjects:\")\n",
    "print(matched_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list = []\n",
    "\n",
    "for file_name in matched_files:\n",
    "    # Ensure full path to the file\n",
    "    full_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    # Check if the file exists before opening it\n",
    "    if os.path.exists(full_path):\n",
    "        with open(full_path, 'r', encoding='utf-8') as file:\n",
    "            sc = json.load(file)\n",
    "\n",
    "        references = sc['abstracts-retrieval-response']['item']['bibrecord']['tail']['bibliography']['reference']\n",
    "\n",
    "        for ref in references:\n",
    "            ref_id = ref.get('@id', '')\n",
    "            fulltext = ref.get('ref-fulltext', '')\n",
    "            publication_year = ref.get('ref-info', {}).get('ref-publicationyear', {}).get('@first', '')\n",
    "            title = ref.get('ref-info', {}).get('ref-title', {}).get('ref-titletext', '')\n",
    "            source_title = ref.get('ref-info', {}).get('ref-sourcetitle', '')\n",
    "\n",
    "            authors = ref.get('ref-info', {}).get('ref-authors', {}).get('author', [])\n",
    "            author_names = [author.get('ce:indexed-name', '') for author in authors]\n",
    "            authors_str = ', '.join(author_names)\n",
    "\n",
    "            ref_list.append({\n",
    "                'id': ref_id,\n",
    "                'fulltext': fulltext,\n",
    "                'year': publication_year,\n",
    "                'title': title,\n",
    "                'source_title': source_title,\n",
    "                'authors': authors_str\n",
    "            })\n",
    "    else:\n",
    "        print(f\"File not found: {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.DataFrame(ref_list)\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "ref_df.replace('', np.nan, inplace=True)\n",
    "\n",
    "ref_df.dropna(inplace=True)\n",
    "\n",
    "# Optionally, reset the index after dropping rows\n",
    "ref_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
